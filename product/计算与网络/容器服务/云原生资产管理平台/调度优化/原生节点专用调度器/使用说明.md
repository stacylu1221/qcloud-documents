

本文向您介绍如何使用原生节点专用调度器。

## 安装原生节点专用调度器
1. 登录 [容器服务控制台](https://console.cloud.tencent.com/tke2/cluster?rid=8)。
2. 在左侧选择**云原生资产管理 > Node Map**。
3. 在“Node Map”页面中，鼠标悬浮到页面下方某一个 Node 上，单击“详情”。
4. 在该 Node 的详情页的右上角，打开“原生节点专用调度器”开关，进行调度器的参数配置。
![](https://qcloudimg.tencent-cloud.cn/raw/4ba513112b247e1714ad149d2bc92b5c.png)
  - **节点 CPU 放大系数**：支持输入1～3之间的数字，保留小数点后一位。
  - **节点内存放大系数**：支持输入1～2之间的数字，保留小数点后一位。
>! 当前节点规格放大系数仅会虚拟放大所有原生节点的规格，该功能有一定的风险：若节点上调度过多的 Pod，且 Pod 真正使用的总资源量大于节点规格，会引发 Pod 的驱逐和重新调度。
  - **作用的 Namespace 范围**：选择指定的 Namespace 后，这些 Namespace 下的所有 Workload 的 Pod 在下次调度时，仅会调度到原生节点上。若原生节点资源不足，会引发 Pod 的 Pending。

## 节点规格放大示例

安装完调度器之后，若指定了节点的 CPU 和内存的放大系数，您可以查看原生节点上和放大系数相关的 Annotation：`expansion.scheduling.crane.io/cpu`, `expansion.scheduling.crane.io/memory`，示例如下：

```yaml
kubectl describe node 10.8.22.108

...
Annotations:        expansion.scheduling.crane.io/cpu: 1.5	# CPU 放大系数
                    expansion.scheduling.crane.io/memory: 1.2	# 内存放大系数
...
Allocatable:
  cpu:                1930m	# 该节点原始可调度资源量
  ephemeral-storage:  47498714648
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             1333120Ki
  pods:               253
...
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests         Limits
  --------           --------         ------
  cpu                960m (49%)       8100m (419%)	# 该节点 Request 和 Limit 占用量
  memory             644465536 (47%)  7791050368 (570%)
  ephemeral-storage  0 (0%)           0 (0%)
  hugepages-1Gi      0 (0%)           0 (0%)
  hugepages-2Mi      0 (0%)           0 (0%)
...
```

**说明：**
- 当前节点原始 CPU 可调度量：1930m
- 节点上所有 Pod 得总 CPU Request 申请量 960m
- 正常情况下，该节点只能最多调度 1930m-960m=970m CPU
- 但实际上该节点 CPU 的可调度量已经被虚拟放大成：1930m*1.5=2895m；实际剩余 CPU 可调度资源为：2895-960 =1935m

此时，创建一个工作负载，只有一个 Pod，CPU 申请量为 1500m，如果没有节点放大的能力，则无法调度到该节点。

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: default
  name: test-scheduler
  labels:
    app: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      nodeSelector:	# 指定节点调度
        kubernetes.io/hostname: 10.8.20.108	# 指定使用被样例中的原生节点
      containers:
      - name: nginx
        image: nginx:1.14.2
        resources:
          requests:
            cpu: 1500m	# 申请量大于放大之前的节点可调度量，但有小于放大之后的节点可调度量
        ports:
        - containerPort: 80
```

该工作负载创建成功：

```yaml
% kubectl get deployment 
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
test-scheduler     1/1     1            1           2m32s

```

再次检查节点的资源占用情况：

```yaml
kubectl describe node 10.8.22.108

...
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests         Limits
  --------           --------         ------
  cpu                2460m (127%)     8100m (419%)	# 该节点 Request 和 Limit 占用量。可以看到，Request 总和超过了节点原始可调度量，节点规格放大成功。
  memory             644465536 (47%)  7791050368 (570%)
  ephemeral-storage  0 (0%)           0 (0%)
  hugepages-1Gi      0 (0%)           0 (0%)
  hugepages-2Mi      0 (0%)           0 (0%)
```
